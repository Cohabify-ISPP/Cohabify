![US Logo](images/logo_us.png)

Report
---

![Cohabify](images/Cohabify.png)

<table>
    <tbody>
        <tr>
            <td rowspan=2>Arriaza Arriaza, Daniel (editor)<p></p> Barrera García, Ismael (editor)<p></p> Calero López, Marina (editor)<p></p> Galeano de Paz, Guillermo (editor)<p></p> González Castillero, Rafael (editor)<p></p> Márquez Sierra, María (editor)<p></p> Márquez Soldán, María (editor)
            </td>
            <td rowspan=2>Morato Navarro, Juan Carlos (revisor,editor) <p></p> Morato Navarro, Olegario (editor)<p></p> Robles Russo, Eduardo (editor)<p></p> Roldán García, Miguel Ángel (editor)<p></p> Romero González, Juan (editor)<p></p> Urquijo Martínez, Álvaro (editor)<p></p>
            </td>
        </tr>
    </tbody>
</table>

<table>
  <tr>
    <th>Grupo</th>
    <th>4</th>
    <th>Entregable</th>
    <th>S2</th>
  </tr>
  <tr>
    <td>Repositorio</td>
    <td colspan="3"><a href="https://github.com/Cohabify/Cohabify">https://github.com/Cohabify/Cohabify</a></td>
  </tr>
  <tr>
    <td>Base de conocimiento común</td>
    <td colspan="3"><a href="https://bgcc.vercel.app/">https://bgcc.vercel.app/</a></td>
  </tr>
</table>


### Versión Cambios Autores
| Versión | Cambios | Autores |
| --- | --- | --- |
| V1.0 | Creación del documento | Álvaro Urquijo Martínez |
| V1.1 | Actualización con información de Sprint 1 | Álvaro Urquijo Martínez, María Márquez Sierra |
| V2.0 | Completada información del Sprint 1 | Juan Carlos Morato, Eduardo Robles, Ismael Barrera |
| V3.0 | Actualización con información de Sprint 2 | Álvaro Urquijo Martínez |


## Tabla de Contenidos

- [Resumen ejecutivo](#resumen-ejecutivo)
- [Información general sobre la BGC](#1-información-general-sobre-la-bgc)
    - [Elección de tecnologías para la BGC](#11-elección-de-tecnologías-para-la-bgc)
    - [Enlace a la base de datos general de conocimiento](#12-enlace-a-la-base-de-datos-general-de-conocimiento)
- [DP](#2-dp)
    - [Feedback general](#21-feedback-general)
        - [Análisis de competidores](#211-análisis-de-competidores)
        - [Análisis de costes](#212-análisis-de-costes)
        - [Análisis de riesgo](#213-análisis-de-riesgo)
        - [Documentación](#214-documentación)
        - [Inicio efectivo](#215-inicio-efectivo)
        - [Modelos de negocio](#216-modelos-de-negocio)
        - [Roles](#217-roles)
        - [Uso de la IA](#218-uso-de-la-ia)
        - [Usuarios piloto](#219-usuarios-piloto)
    - [Feedback recibido por nuestro grupo](#22-feedback-recibido-por-nuestro-grupo)
    - [Acciones de respuesta ante el feedback](#23-acciones-de-respuesta-ante-el-feedback)
        - [Análisis de competidores](#231-análisis-de-competidores)
        - [Análisis de costes](#232-análisis-de-costes)
        - [Análisis de riesgo](#233-análisis-de-riesgo)
        - [Documentación](#234-documentación)
        - [Inicio efectivo](#235-inicio-efectivo)
        - [Modelos de negocio](#236-modelos-de-negocio)
        - [Roles](#237-roles)
        - [Uso de la IA](#238-uso-de-la-ia)
        - [Usuarios piloto](#239-usuarios-piloto)
        - [Feedback específico de grupo](#2310-feedback-específico-de-grupo)
- [S1](#3-s1)
    - [Feedback general](#31-feedback-general)
    - [Feedback recibido por nuestro grupo](#32-feedback-recibido-por-nuestro-grupo)
    - [Acciones de respuesta ante el feedback](#33-acciones-de-respuesta-ante-el-feedback)
        - [Análisis de competidores](#331-análisis-de-competidores)
        - [Análisis de costes](#332-análisis-de-costes)
        - [Análisis de riesgo](#333-análisis-de-riesgos)
        - [Documentación](#334-documentación)
        - [Inicio efectivo](#335-inicio-efectivo)
        - [Modelos de negocio](#336-modelos-de-negocio)
        - [Roles](#337-roles)
        - [Uso de la IA](#338-uso-de-la-ia)
        - [Usuarios piloto](#339-usuarios-piloto)
        - [Feedback específico de grupo](#3310-feedback-específico-de-grupo)
- [S2](#4-s2)
    - [Feedback general](#41-feedback-general)
    - [Feedback recibido por nuestro grupo](#42-feedback-recibido-por-nuestro-grupo)
    - [Acciones de respuesta ante el feedback](#43-acciones-de-respuesta-ante-el-feedback)
        - [Análisis de competidores](#431-análisis-de-competidores)
        - [Análisis de costes](#432-análisis-de-costes)
        - [Análisis de riesgo](#433-análisis-de-riesgo)
        - [Documentación](#434-documentación)
        - [Inicio efectivo](#435-inicio-efectivo)
        - [Modelos de negocio](#436-modelos-de-negocio)
        - [Roles](#437-roles)
        - [Uso de la IA](#438-uso-de-la-ia)
        - [Usuarios piloto](#439-usuarios-piloto)
        - [Feedback específico de grupo](#4310-feedback-específico-de-grupo)



# Resumen ejecutivo

En el siguiente documento, se presentarán los aportes realizados por el grupo 4 a la base de datos de conocimiento de la asignatura. Esta consistirá en dos partes, una primera parte analizando el feedback general recibido en la sesión de clase, que solamente será relevante en ciertos casos, ya que estos datos solo serán aportados cuando nuestro grupo sea el primero en exponer, y la segunda parte en la que se comentará el feedback tomado por nuestro grupo de parte de profesores y alumnos, en referencia a nuestro propio grupo.

# 1. Información general sobre la BGC

## 1.1 Elección de tecnologías para la BGC

Para establecer una base de datos general de conocimiento que satisfaga las necesidades del alumnado, y tras una puesta en común con los representantes de todos los grupos, se decidió usar Docusaurus, un generador de sitios estáticos especializado en la producción de sitios web de documentación. Se ha subido a un repositorio de GitHub, y se les ha dado permiso a un representante de cada grupo para gestionar este repositorio.

Además, se ha implementado un despliegue automático en Vercel para tener la aplicación operativa en línea siempre con la última versión de esta.

## 1.2 Enlace a la base de datos general de conocimiento

La base de datos de conocimiento puede ser encontrada visitando el siguiente enlace:

<https://bgcc.vercel.app/>

El repositorio de Github, desde donde se hacen los despliegues automáticos, se encuentra en el siguiente enlace:

<https://github.com/ISPP-2324/BGC>

# 2. DP

## 2.1 Feedback general

En nuestro proyecto colaborativo, la retroalimentación periódica es esencial para mejorar continuamente y maximizar la eficacia del equipo. Sin embargo, debido a un acuerdo entre el resto de grupos de mañana, se ha tomado la decisión colectiva de que sólo el grupo con el primer turno de presentación por semana se encargará de recoger dicho feedback. Esto ha llevado a nuestro grupo a no poder proporcionar retroalimentación en las últimas dos semanas, puesto que no hemos sido los primeros en presentar.

Además, problemas organizativos relacionados con la base de datos y la coordinación entre representantes han surgido, ya que ningún grupo ha subido sus contribuciones al proyecto hasta la fecha límite del domingo 18 de febrero. En respuesta, nuestro equipo ha decidido compartir nuestras contribuciones para mantener el impulso del proyecto y promover una cultura de colaboración y transparencia. En este documento, analizaremos nuestras contribuciones y los desafíos que enfrentamos hacia nuestros objetivos comunes.

### 2.1.1 Análisis de competidores

**Semana 2**

+ Se sugiere realizar un análisis minucioso de cada competidor, considerando sus fortalezas y debilidades.
+ Dedicar tiempo a entender a fondo el contexto y posición de cada competidor en el mercado.

### 2.1.2 Análisis de costes

**Semana 1**

+ Asegurarse de tener un plan claro y realista en términos de tiempo.
+ Considerar la viabilidad de las metas dentro del plazo establecido.

**Semana 2**

+ Considerar la inclusión de una tabla con los costes mensuales estimados.
+ Detallar los costes específicos, como herramientas, licencias y otros gastos asociados.
+ Proporcionar evidencia del seguimiento del presupuesto.

### 2.1.3 Análisis de riesgo

**Semana 1**

+ Identificar eventos de riesgo y establecer planes de contingencia.
+ Diferenciar entre problemas y riesgos, abordándolos de manera distinta.
+ Presentar medidas preventivas y correctivas para cada riesgo identificado.
+ Asegurarse de que las medidas sean claras, efectivas y aplicables en el tiempo.

**Semana 2**

+ Condensar la información sobre riesgos en diapositivas más concisas.
+ Proporcionar un resumen claro de las estrategias de mitigación para cada riesgo.
+ Incluir la probabilidad de cada riesgo y la efectividad prevista de las medidas de mitigación.
+ Utilizar íconos o indicadores visuales para representar el estado de cada riesgo en las presentaciones.

### 2.1.4 Documentación

**Semana 1**

+ Necesidad de definir políticas de commits, convenciones de nombrado de variables, métodos y ramas.
+ Establecer prácticas claras para mantener una estructura organizada en el repositorio.

**Semana 2**

+ Destacar la importancia de entregar evidencias del trabajo realizado, como documentos y registros de actividades.
+ Revisar y proporcionar documentos que respalden el progreso y los logros alcanzados.
+ Establecer un seguimiento regular del Commitment Agreement (CA) y actualizar su estado semanalmente.

### 2.1.5 Inicio efectivo

**Semana 1**

+ Utilizar un "killer opener" que genere interés y establezca el tono de la presentación.
+ Transicionar adecuadamente desde el enganche inicial al contenido principal.
+ Sugerir una presentación que siga un orden lógico y efectivo.
+ Colocar las promesas o elementos destacados al inicio o en puntos estratégicos de la presentación.

**Semana 2**

+ Enfocarse en causar una impresión inicial positiva y memorable.
+ Considerar anécdotas o ejemplos relacionados con la convivencia para generar empatía (Metáfora con Dori y Dumbo).
+ Buscar un equilibrio adecuado en las interacciones entre profesores y alumnos durante la presentación.
+ Asegurarse de que las interacciones contribuyan al flujo y comprensión de la presentación.
+ Utilizar este método para fomentar la participación y mantener la atención del público.

### 2.1.6 Modelos de negocio

**Semana 1**

+ Detallar claramente el modelo de negocio, incluyendo planes de suscripción y promociones.
+ Considerar la incorporación de medidas de seguridad, como la valoración y ocultación parcial de la dirección.
+ Evitar asociar roles específicos a personas y adoptar un enfoque más flexible.
+ Reconocer que una persona puede desempeñar varios roles a lo largo del tiempo.
+ Dedicar más tiempo a describir casos de uso mínimos y esenciales.

**Semana 2**

+ Evaluar la posibilidad de subir una foto del contrato para validar la propiedad.
+ Proponer la verificación del usuario mediante DNI y foto al momento del inicio de sesión.
+ Contemplar planes futuros.
+ Proporcionar un enfoque claro y efectivo para mantener la coherencia y comprensión.

### 2.1.7 Roles

**Semana 2**

+ Introducir roles específicos, como el rol de mantenimiento, para mejorar la gestión de la plataforma.
+ Tener cuidado con el tema de la comunicación en caso de rotación de roles.

### 2.1.8 Uso de la IA

**Semana 1**

+ Evaluar la posibilidad de incorporar inteligencia artificial (IA) en el proyecto.

**Semana 2**

+ Proporcionar detalles específicos sobre cómo se integrará la IA en el proyecto.
+ Especificar las áreas o funciones específicas en las que se utilizará la IA.

### 2.1.9 Usuarios piloto

**Semana 1**

+ Se sugiere realizar una exploración detallada de posibles usuarios piloto.
+ Analizar sus necesidades y características para una selección más efectiva.
+ Proponer una identificación clara de segmentos de usuarios piloto.
+ Definir criterios específicos para la elección de estos usuarios.

**Semana 2**

+ Asegurarse de tener una gestión adecuada de los usuarios piloto.
+ Garantizar una comunicación efectiva y obtener retroalimentación valiosa de estos usuarios.
+ Realizar un estudio detallado de los usuarios piloto seleccionados. + Comprender sus comportamientos, preferencias y expectativas.
+ Discutir la posibilidad de introducir innovaciones tecnológicas específicas para los usuarios piloto.
+ Personalizar la experiencia según las necesidades y preferencias identificadas.
+ Estar abierto a realizar ajustes en el producto según el feedback recibido de los usuarios piloto.
+ Utilizar esta fase como una oportunidad para mejorar y adaptar el producto.
+ Acuerdo de compromiso: En este documento vamos a encontrar feedback dado respecto al acuerdo de compromiso.
+ En cuanto al commitment agreement, se recomienda revisar el agreement y ver el estado en el que está el acuerdo. Monitorizar el cumplimiento de dicho agreement por parte de cada miembro del equipo. Versionar el agreement para cada cambio que se haga. Añadir apartado con responsable de cada tarea, así luego se verifican las responsabilidades. Plantear créditos de servicio.

## 2.2 Feedback recibido por nuestro grupo

### Semana 1: 06/02

+ Reducir el número de personas que exponen, ya que puede suponer una distracción para el público.
+ Detallar el modelo de negocio, medidas de seguridad y verificación de la existencia del piso.
+ Está bien no asociar roles a personas, sino que todo el mundo sea multidisciplinar. Pero en los roles que sí se definan, como el PM, es importante la comunicación entre el anterior y el nuevo, y hay que determinar ciertas medidas para no sobrecargar al nuevo con cosas que no hizo el anterior.
+ Trabajar en la seguridad ante bots. Para ello, se puede verificar a los usuarios mediante algún método como DNI, foto o similares.
+ Implementar un reloj de equipo para saber cómo se está invirtiendo el tiempo.
+ Describir casos de uso mínimos de una manera más exhaustiva para que la audiencia pueda entender la diferencia entre ellos.
+ Se podría validar la existencia del piso para garantizar la seguridad. Se propone usar el código de catastro o algún similar.

### Semana 2: 13/02

+ Conveniente la definición de políticas de commits y convenciones.
+ Sugerencia de hablar de tecnologías de comunicación y control del tiempo.
+ Falta de información sobre cómo se administrará el uso de inteligencia artificial.
+ Falta un inicio efectivo, al parecer el silencio no es un inicio efectivo.
+ Entregar documento de TCO, ya que se ha elaborado exhaustivamente.
+ Identificar cliente, en nuestro caso podría ser el usuario.
+ Mejorar el análisis de competidores. Explicar por qué se excluyen competidores, usar herramientas para buscar competidores, buscar keywords,...
+ Replantear pricing sobre lo que nos diferencia del resto (Realmente se ha explicado mal lo que nos diferencia del resto, que son los chats grupales)
+ Desarrollar la idea de usar etiquetas de usuario.
+ No pasar diapositivas dando por hecho que ya está explicado.
+ Resumir texto de los planes de contingencia de riesgos.
+ Hacer seguimiento de riesgos en cada iteración.
+ Si el riesgo es muy probable, hay que actuar antes de que ocurra, no solo cuando ocurra.
+ Hacer seguimiento de que se siga el commitment agreement.
+ Indicar transparencias en los que se ha aplicado el feedback anterior con un icono.
+ Los mocks al final mejoran la fluidez puesto que no cortan la presentación.
+ No queda claro la geolocalización por rango.
+ Disonancia entre algunas imágenes y lo explicado.
+ No separar los costes de producción del TCO, puesto que dichos costes son parte de él.
+ Sintetizar la información del TCO.

## 2.3 Acciones de respuesta ante el feedback

Todo el feedback anotado se ha tenido en cuenta y se ha revisado usando una checklist con el objetivo de mejorar y no repetir los mismos errores. En los próximos entregables se marcarán las evidencias de estas correcciones para que quede constancia de nuestra respuesta al feedback.

### 2.3.1 Análisis de competidores

Tras dos semanas sin terminar de realizar correctamente la tarea de análisis de competidores se han cambiado a los responsables de realizar dicho análisis y se ha intentado realizar una búsqueda más en detalle intentando cubrir todo el feedback que se recibió referente a esta tarea.

### 2.3.2 Análisis de costes

Para el análisis de costes se ha realizado una estimación en base al tiempo total que se debe cursar en la asignatura (150 h/persona) y se han tenido en cuenta las herramientas que se utilizan dentro de los cálculos del TCO, además de ser calculado mensualmente para mayor precisión a la hora de establecer un pricing competitivo.

### 2.3.3 Análisis de riesgos

Se han tomado medidas para resumir la información de manera que quede clara a la hora de ser presentada en diapositivas y cada riesgo ha sido analizado meticulosamente para establecer un plan de contingencia a modo de prevención, añadiendo además su impacto y probabilidad de aparición.

### 2.3.4 Documentación

La documentación generada para realizar tareas como el cálculo de TCO se han pasado a limpio para ser presentadas junto con el resto de documentación dado el interés del profesorado por ver más en detalle los procesos y razonamientos seguidos por el equipo para llevar a cabo dichas actividades.

### 2.3.5 Inicio efectivo

A partir de las próximas sesiones, se aplicarán diversas prácticas de inicio efectivo, de manera que encontremos el mejor posible de cara a la presentación final. Por supuesto, se evitará como inicio efectivo el silencio prolongado de la semana 2.

### 2.3.6 Modelos de negocio

Se ha trabajado en esclarecer la idea de negocio, incluyendo planes para los futuros usuarios ofreciéndoles funciones interesantes que nos permitan competir en el mercado. En la semana 2 se nos aconsejó potenciar nuestras diferencias con los demás competidores y ya se están estudiando formas de mejorar en este aspecto.

### 2.3.7 Roles

No se han realizado actuaciones de consolidación.

### 2.3.8 Uso de la IA

No se plantea integrar la inteligencia artificial para ser usada dentro de la aplicación pero sí se han establecido medidas para documentar el uso de la IA durante el desarrollo de Cohabify. Dichas medidas quedan registradas en el documento **AI-Usage.md**.

### 2.3.9 Usuarios piloto

Se han estudiado las necesidades del sistema en cuanto a usuarios piloto (estudiantes, propietarios, estudiantes técnicos y entre otros), se ha definido de qué forma se gestionan, tanto los grupos en los que se dividirán conforme se vaya avanzando en el proyecto para probar los distintos planes de pricing, como se realizará la comunicación con todos ellos, la forma de recoger el feedback, cómo formaremos a los usuarios para que entiendan sobre la aplicación y su objetivo siendo usuarios pilotos y las recompensas que obtendrán por ayudarnos a probar el sistema. El documento que recoge todos los puntos mencionados es **Pilot_users.md**.

### 2.3.10 Feedback específico de grupo

El feedback dado a nuestro grupo en específico se ha implementado en su totalidad, y se están indicando a partir de la tercera presentación las diapositivas donde esto se puede ver reflejado.

# 3. S1

## 3.1 Feedback  general

Dado que esta semana nuestro grupo no estaba encargado de aportar el feedback general a la DB, procedemos a dejar este apartado intencionadamente en blanco.

## 3.2 Feedback recibido por nuestro grupo

### Semana 3: 20/02

+ Mejorar el inicio efectivo.
+ Hacer uso del micrófono si es necesario.
+ Desglosar el TCO.
+ A la hora de mostrar el pricing, primero mostrar todos los planes y luego detallar cada uno.
+ Falta la Landing Page.
+ Añadir estadísticas sobre IA y desarrollo (cantidad de pull requests, si se ha usado mucho o no la IA).
+ Buscar usuarios piloto como estudiantes que buscan piso.
+ Cambiar los mockups para que contengan imágenes más realistas.

### Semana 4: 27/02

+ Resumen monótono en la presentación
+ Para el versionado de documentos se crea una carpeta de documentos y al final de cada semana se saca el pdf con un número de versión actualizado.
+ Falta el elevator pitch.
+ Leer las diapositivas si son largas para mantener la atención del público.
+ Más apoyo visual para el elevator pitch.
+ Especificar qué es la categoría "otros" en los usuarios piloto o eliminarla.
+ Trazar planificación sobre cómo tratar a los usuarios piloto.
+ Hablar de porcentajes cuando se hable de usuarios al mes.
+ Especificar cómo escala el tco y los beneficios con más usuarios.
+ Añadir estadísticas del INE.
+ Para regular el CA, si en una semana no se llega al 80, en la siguiente se hace un 120.
+ El rendimiento debe ser relativo al número de horas que se deben dedicar.
+ Definir a qué nota aspira cada miembro del grupo y especificarlo en el CA.
+ Especificar qué tareas hace cada subgrupo, con un pseudodiagrama de Gantt.
+ Para la retrospectiva, en vez de poner un tablero, poner un resumen.
+ Los problemas deben tener una propuesta de mejora, objetivo de mejora y la medición de cómo de efectiva es.
+ En la última columna de análisis de rendimiento, indicar con unas flechas verdes o rojas si el rendimiento está mejorando o empeorando.![ref2]
+ Considerar ventajas y desventajas de una demo en directo o grabada.
+ Dividir los sprints 2 y 3 en diapositivas aparte para evitar confusión sobre qué se hace en cada uno.
+ Evitar hablar mal de los competidores y añadir más.

## 3.3 Acciones de respuesta ante el feedback

Todo el feedback anotado se ha tenido en cuenta y se ha revisado usando una checklist con el objetivo de mejorar y no repetir los mismos errores. En los próximos entregables se marcarán las evidencias de estas correcciones para que quede constancia de nuestra respuesta al feedback.

### 3.3.1 Análisis de competidores

Se ha añadido budi a la lista de principales competidores en la presentación, y se ha hecho un estudio más exhaustivo de las cualidades de este competidor.

### 3.3.2 Análisis de costes

Se ha dividido el TCO en CapEx y OpEx. Además, se ha buscado información sobre el número de personas que buscan piso compartido según el INE y un estudio de Fotocasa, para así estimar el número de usuarios según el método PERT: número de usuarios optimista, pesimista y realista. Por otra parte, se ha estimado qué cambios habría que hacer en los servicios y en los ingresos y beneficios en caso de tener la base de usuarios pesimista y optimista.

### 3.3.3 Análisis de riesgos

No se han realizado actuaciones de consolidación.

### 3.3.4 Documentación

Se ha decidido utilizar un nuevo mecanismo de versionado para facilitar el trabajo del equipo, especialmente para diferenciar el trabajo nuevo de cara a las presentaciones.

### 3.3.5 Inicio efectivo

Se tratará de enlazar correctamente el inicio efectivo con el inicio de la presentación de manera que no haya tanto contraste, y por tanto, evitaremos arriesgar perder la atención conseguida con el opener.

### 3.3.6 Modelos de negocio

No se han realizado actuaciones de consolidación.

### 3.3.7 Roles

Se ha establecido la posibilidad de rotación de los roles con mayores responsabilidades (GMs), resultando este en la rotación voluntaria de uno de los 3 GMs inicialmente asignados.

### 3.3.8 Uso de la IA

Hemos creado estas tres páginas en la Wiki de Github para que todo el mundo pueda poner el uso de la IA que le ha dado en el proyecto. La idea es tener los prompts específicos para qué han hecho que nos deje las mejores respuestas. Estas son las entradas:

- [**Prompts of ChatGPT**](https://github.com/Cohabify/Cohabify/wiki/Prompts-of-ChatGPT): En esta página pondremos el directorio, la duda o error y la conversación compartida por un enlace dando las respuestas que nos dio sobre esa duda ChatGPT.
- [**Prompts of Copilot**](https://github.com/Cohabify/Cohabify/wiki/Prompts-of-Copilot): En esta página pondremos los prompts que hemos proporcionado en Copilot. Estas dudas serán normalmente de código ya que por experiencia este suele tener mejor calidad de respuesta que ChatGPT.
- [**Transcriptions of Whisper**](https://github.com/Cohabify/Cohabify/wiki/Transcriptions-of-Whisper): En esta página pondremos todas los resultados de las transcripciones que nos haga Whisper. Whisper es una inteligencia artificial capaz de transcribir un archivo de audio a texto y es muy útil a la hora de recoger información relevante de una reunión.
### 3.3.9 Usuarios piloto

Hemos creado un correo para utilizarlo como cuenta de soporte y comunicación con los usuarios piloto (<cohabify.soporte@gmail.com>). Se ha comunicado por correo un anuncio a los usuarios pilotos del grupo 10 de ISPP con instrucciones de uso, además de enlaces a la aplicación, landing page y a una encuesta para recoger el feedback de los usuarios. Se crearán tutoriales en formato de vídeo y pdf para los usuarios piloto en próximas entregas. Además, se ha contactado con otros usuarios piloto, que participarán en la siguiente fase de pilotaje.

### 3.3.10 Feedback específico de grupo

El feedback dado a nuestro grupo en específico se ha implementado en su totalidad dentro de las capacidades del grupo.


# 4. S2
## 4.1 Feedback general

En este apartado se recogerá feedback aportado a todos los grupos o información util general aportada durante la semana, estará dividido en apartados.

- Análisis de Competidores:
  - Dejar claras las diferencias de nuestro producto con nuestros competidores.

- Análisis de Costes:
  - Hacer costes vs beneficios a 24 meses vista. (TCO a dos años).
  - Para la semana del 02/04 se pide un resumen del TCO con Capex/Opex.

- Análisis de Riesgo:
  - Es necesario tener planes de contingencia por si algun miembro tuviera algún problema (En especial si se trata de un presentador que no pueda presentar).

- Documentación:
  - Reflejar en el Commitment Agreement las formulas usadas para la evaluación de miembros del equipo.

- Inicio efectivo:
  - Si se hace algun inicio que requiera sonido, asegurarse antes de la presentación que el volumen sea adecuado.

- Presentación:
  - En la demo se deben poner tanto datos como imagenes reales
  - Ver como otras empresas enfocan el elevator pitch para aplicarlo en el nuestro.
  - Hacer zoom en la demo para que se aprecie mejor.
  - Resaltar información y cosas que aporten valor, no lo estético.
  - Resaltar en el storyboard lo que nos diferencia de los competidores.
  - Citar las fuentes usadas.
  - Mostrar el impacto legal del proyecto (GDPR, licencias, aspectos legales, customer agreement).
  - Realizar Storyboard para un rol distinto.

- Proyecto en general:
  - Se debe realizar una justificación si se quiere recortar el alcance.
  - Se debería usar una API para comprobar que los correos sean válidos.
  - Utilizar un calendario compartido.
  - Hacer mejor uso de los conventional commits (Por ejemplo con changelogs automáticos).

- Roles:
  - Sería buena idea rotar los presentadores. Para que todos los miembros tengan la experiencia de presentar.

- Uso de la IA:
  - Mostrar las lecciones aprendidas con la IA o algo interesante relacionado con estas.
  - Importancia en las alucinaciones (Cuantos prompt se hacen hasta obtener la respuesta que buscamos).

- Usuarios Piloto:
  - Mostrar que se esté de acuerdo con el customer agreement realizado.


## 4.2 Feedback recibido por nuestro grupo

### Semana 5: 05/03

+ Falta el estado de los usuarios piloto.
+ Poner el número de las diapositivas alto para que se vea mejor desde atrás.
+ Orden de "Uso de las IAs" y "Usuarios piloto" incorrectos.
+ Poner fotos de apoyo en el killer opener.
+ Grabar presentación está bien, pero hacer más zoom.
+ No perder tiempo rellenando formularios, precargarlos.
+ No usar la misma fórmula de rendimiento para todos los roles.
+ Las tareas de coordinación no se miden como puntos de historia.
+ Añadir login social.
+ La matriz RACI debe corresponder con el github.
+ Ver como medir las acciones de mejora para los problemas.

### Semana 6: 12/03 (Retrospectiva)

+ Ajustar la linea ideal a lo real, no aplicarnos fines de semana/fiesta y usar nuestro calendario de horas
+ Usar una épica/milestone que reuna las issues de refactorización
+ Separar la nota de desarrollo y coordinación y medir el grado de satisfacción del grupo con respecto al GM. (Para que el bajo rendimiento de un miembro del grupo no le afecte).
+ Usar gráfica de control chart para ver la diferencia entre tareas que se entregan antes y más tarde, buscar que el control chart llegue lo más cercano a la media para mostrar la equidad entre las tareas.
+ Poner issues de control de calidad para saber si la planificación está bien definida
+ Realizar acuerdo con grupo de usuarios piloto para asegurar que ambas partes cumplen el trabajo en el tiempo que se requiere.
+ Mostrar perfiles de github y clockify.
+ Ver puntuaciones proporcionadas y tareas asignadas a cada individuo. 

### Semana 7: 19/03

+ Comprobar el volumen antes de la presentación para evitar problemas.
+ No confundir Commitment Agreement con Customer Agreement.
+ Facilitar un enlace para el GDPR Y terminos de uso.
+ Poner datos realistas en la demo.
+ Hacer mayor énfasis en diferencias con los competidores.
+ Indicar estado de los problemas y métricas para medir si se están solucionando.
+ Justificar el recorte en el alcance.
+ Mejorar elevator pitch.

## 4.3 Acciones de respuesta ante el feedback

Todo el feedback anotado se ha tenido en cuenta y se ha revisado usando una checklist con el objetivo de mejorar y no repetir los mismos errores. En los próximos entregables se marcarán las evidencias de estas correcciones para que quede constancia de nuestra respuesta al feedback.

### 4.3.1 Análisis de competidores

No procede.

### 4.3.2 Análisis de costes

En el TCO se ha añadido, en la tabla de costes de operación, una nueva columna con la estimación a 24 meses.

### 4.3.3 Análisis de riesgos

No procede.

### 4.3.4 Documentación

Se ha corregido la confusión entre Customer Agreement y Commitment Agreement, creando el Customer Agreement y el de Privacy Policy.

### 4.3.5 Inicio efectivo

No procede.

### 4.3.6 Modelos de negocio

No procede.

### 4.3.7 Roles

No procede.

### 4.3.8 Uso de la IA

Se ha añadido una página nueva en la wiki para los Prompts de Phind. Una IA que utiliza un modelo propio y además tiene la capacidad de realizar búsquedas en Internet para dar respuestas actualizadas

### 4.3.9 Usuarios piloto

Hemos creado documentos de Customer Agreement y Commitment Agreement para controlar el pilotaje de nuestra aplicación de forma más precisa.

### 4.3.10 Feedback específico de grupo

El feedback dado a nuestro grupo en específico se ha implementado en su totalidad dentro de las capacidades del grupo.
